import time
import io
import math 
import torch
import pandas as pd
import numpy as np
from EDA import EDA
from Multiple_Lines import MultipleLines
import streamlit as st
import tensorflow as tf
from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, make_scorer
from sklearn.model_selection import KFold
from sklearn.model_selection import RandomizedSearchCV
from scikeras.wrappers import KerasRegressor
from tensorflow.keras.layers import Dense, LSTM, Conv1D, LeakyReLU, Flatten, MaxPooling1D, SimpleRNN
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
tf.get_logger().setLevel('ERROR')

st.set_page_config(page_title="Forecast Time Series",page_icon=":bar_chart:",layout="centered")

st.write("# Dá»° ÄOÃN Báº°NG Máº NG NÆ -RON TÃCH CHáº¬P (CONVOLUTIONAL NEURAL NETWORK)")
st.divider()
st.sidebar.write("# Thiáº¿t láº­p mÃ´ hÃ¬nh")

# ------------------------- Biáº¿n toÃ n cá»¥c ------------------------- #
df = None
df_target = None
df_scaled = None
model = None
d = None
t = None
train_size = None
degree = None
unit = None
epoch= None
batch_size = None
m = None
scaler = None
test_size = None
train = None
test = None
train_time = None
test_time = None
predict = None
actual = None
info_table = None
result_table = None
metric_table = None
metrics = None
learning_rate = None
generator = None
discriminator = None
model_training = None

# ------------------------- Function ------------------------- #
# load data.csv
@st.cache_data
def LoadData(uploaded_file):
    df = pd.read_csv(uploaded_file)
    return df

#TÃ­nh CV_RMSE
@st.cache_data
def CV_RMSE(predict, actual):
    # Sá»‘ lÆ°á»£ng fold (cháº³ng háº¡n, 5-fold cross-validation)
    num_folds = 5

    # Khá»Ÿi táº¡o K-fold cross-validation
    kf = KFold(n_splits=num_folds)
    # Táº¡o danh sÃ¡ch Ä‘á»ƒ lÆ°u káº¿t quáº£ RMSE tá»« tá»«ng fold
    rmse_scores = []

    for train_index, test_index in kf.split(actual):
        predicted_test, actual_test = predict[test_index], actual[test_index]
        
        mse = mean_squared_error(actual_test, predicted_test)
        rmse = math.sqrt(mse)
        
        rmse_scores.append(rmse)

    # TÃ­nh tá»•ng RMSE tá»« cÃ¡c fold vÃ  tÃ­nh RMSE trung bÃ¬nh
    average_rmse = np.mean(rmse_scores)
    return average_rmse

# HÃ m Ä‘Ã¡nh giÃ¡
@st.cache_data
def Score(predict, actual):
    mae = mean_absolute_error(actual, predict)
    mse = mean_squared_error(actual, predict)
    rmse = np.sqrt(mse)
    mape = np.mean(np.abs((actual - predict) / predict))
    cv_rmse = CV_RMSE(predict,actual)
    return mae, mse, rmse ,mape ,cv_rmse



# XÃ³a dá»¯ liá»‡u lÆ°u trong streamlit
def ClearCache():
    st.session_state.clear()

def dfs_tabs(df_list, sheet_list):

    output = io.BytesIO()

    writer = pd.ExcelWriter(output,engine='xlsxwriter')   
    for dataframe, sheet in zip(df_list, sheet_list):
        dataframe.to_excel(writer, sheet_name=sheet, startrow=0 , startcol=0)   
    writer.close()

    processed_data = output.getvalue()
    return processed_data

if 'clicked_train' not in st.session_state:
    st.session_state.clicked_train = False

def click_button_train():
    st.session_state.clicked_train = True

if 'clicked_save' not in st.session_state:
    st.session_state.clicked_save = False
if 'display_info' not in st.session_state:
        st.session_state.display_info = {}
def click_button_save():
    st.session_state.clicked_save = True
    

#--------------------------------------
# Sidebar
# Chá»n mÃ´ hÃ¬nh
mod = st.sidebar.selectbox(
    "Chá»n mÃ´ hÃ¬nh:",
    ["CNN", "LSTM","RNN"],
    on_change=ClearCache).lstrip('*').rstrip('*')

# Chá»n ngÃ y Ä‘á»ƒ dá»± Ä‘oÃ¡n
col1, col2 = st.sidebar.columns(2)
with col1:
    input_dim = st.number_input('**Sá»‘ ngÃ y dÃ¹ng Ä‘á»ƒ dá»± Ä‘oÃ¡n:**',
                            value=7, step=1, min_value=1, on_change=ClearCache)

with col2:
    output_dim = st.number_input('**Sá»‘ ngÃ y muá»‘n dá»± Ä‘oÃ¡n:**', value=1,
                            step=1, min_value=1, on_change=ClearCache)

# Chá»n tá»‰ lá»‡ chia táº­p train/test
train_size = st.sidebar.slider('**Tá»‰ lá»‡ training**', 10, 70, 70, step=10)
valid_size = st.sidebar.slider('**Tá»‰ lá»‡ Validation**', 10, 90 - train_size, 20, step=10)
train_ratio = train_size/100
valid_ratio = valid_size/100

activation = st.sidebar.selectbox(
    '**Chá»n Activation funcion**', ('ReLU', 'LeakyReLU', 'tanh'), on_change=ClearCache)


scaler = st.sidebar.selectbox(
    '**Chá»n phÆ°Æ¡ng phÃ¡p chuáº©n hÃ³a dá»¯ liá»‡u**', ('Min-Max', 'Zero-Mean', 'Dá»¯ liá»‡u gá»‘c'), on_change=ClearCache)

# Chá»n táº­p dá»¯ liá»‡u
st.header("Chá»n táº­p dá»¯ liá»‡u tiáº¿n hÃ nh huáº¥n luyá»‡n")
uploaded_file = st.file_uploader(
    "Chá»n tá»‡p dá»¯ liá»‡u", type=["csv"], on_change=ClearCache)


def LSTM_Model(input_dim=10, output_dim=1, units =32, learning_rate=0.0001, activation = 'relu') -> tf.keras.models.Model:
    model = Sequential()
    model.add(LSTM(units=units, return_sequences=True, input_shape=(input_dim, 1), activation=activation))
    model.add(LSTM(units=units, activation=activation))
    model.add(Dense(32, activation=activation))
    model.add(Dense(units=output_dim))
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')
    return model

def RNN_Model(input_dim=10, output_dim=1, units =32, learning_rate=0.0001, activation = 'relu') -> tf.keras.models.Model:
    model = Sequential()
    model.add(SimpleRNN(units=units, return_sequences=True, input_shape=(input_dim, 1), activation=activation))
    model.add(SimpleRNN(units=units, activation=activation))
    model.add(Dense(32, activation=activation))
    model.add(Dense(units=output_dim))

    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')
    return model

def CNN_Model(input_dim=10, output_dim=1, units = 32, learning_rate = 0.0001, activation = 'relu'):
    model = Sequential()
    # ThÃªm lá»›p Convolutional 1D Ä‘áº§u tiÃªn
    model.add(Conv1D(units, input_shape=(input_dim, 1), kernel_size=3, strides=1, padding='same', activation=activation)) 
    model.add(Conv1D(units, kernel_size=3, strides=1, padding='same', activation=activation))
    model.add(MaxPooling1D(pool_size=2,strides=2, padding='same'))
    # HoÃ n thiá»‡n mÃ´ hÃ¬nh
    model.add(Flatten())
    model.add(Dense(220, use_bias=True))
    model.add(LeakyReLU())
    model.add(Dense(220, use_bias=True, activation=activation))
    model.add(Dense(units=output_dim))
    # Thiáº¿t láº­p cáº¥u hÃ¬nh cho mÃ´ hÃ¬nh Ä‘á»ƒ sáºµn sÃ ng cho quÃ¡ trÃ¬nh huáº¥n luyá»‡n.
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')
    return model
def CNN_Retrain(input_dim=10, output_dim=1):
    # define model
    model = Sequential()
    model.add(Conv1D(filters=16, kernel_size=3, activation='relu', input_shape=(input_dim,1)))
    model.add(MaxPooling1D(pool_size=2))
    model.add(Flatten())
    model.add(Dense(10, activation='relu'))
    model.add(Dense(output_dim))
    model.compile(loss='mse', optimizer='adam')
    return model

if uploaded_file is not None:
    file_name = uploaded_file.name
    df = LoadData(uploaded_file)

    # Chá»n cá»™t dá»± Ä‘oÃ¡n & activation function
    selected_predict_column_name = st.sidebar.selectbox(
        '**Chá»n cá»™t Ä‘á»ƒ tiáº¿n hÃ nh training:**', tuple(df.drop(df.columns[0],axis = 1).columns.values), on_change=ClearCache)
    # Táº¡o Ä‘á»‘i tÆ°á»£ng EDA
    eda = EDA(df = df, n_steps_in = input_dim, n_steps_out = output_dim, feature=selected_predict_column_name, train_ratio = train_ratio, valid_ratio = valid_ratio, scaler = scaler)

    # ThÃ´ng tin táº­p dá»¯ liá»‡u
    st.subheader('Táº­p dá»¯ liá»‡u ' + file_name)
    st.write(df)

    # Váº½ biá»ƒu Ä‘á»“ Ä‘Æ°á»ng cho táº­p dá»¯ liá»‡u
    st.subheader('Trá»±c quan hÃ³a táº­p dá»¯ liá»‡u ' + file_name)

    column_names = eda.data_old.columns.tolist()
    selected_column_name = st.selectbox("**Chá»n cá»™t:**", column_names)
    fig = MultipleLines.OneLine(eda, selected_column_name)
    st.plotly_chart(fig)

    df_target = df[selected_column_name]
    
    # Optimize Model
    if st.sidebar.button('Optimize Model', type="primary"):
        st.divider()
        st.header("Optimize MÃ´ HÃ¬nh")
        with st.spinner('Äang tiáº¿n hÃ nh Optimize...'):
            start_time = time.time()
            
            param_dist = {
            'units': [16, 32, 64, 128, 256],
            'epochs': range(1, 101),
            'batch_size': [16, 32, 64, 128, 256],
            'learning_rate': [0.0001]
            }
            if mod == 'CNN':
                m = KerasRegressor(model = CNN_Model, input_dim=input_dim, output_dim=output_dim, units =32, learning_rate = 0.0001, activation= activation)

            elif mod == 'LSTM':
                m =  KerasRegressor(model=LSTM_Model, input_dim=input_dim, output_dim=output_dim, units =32, learning_rate = 0.0001, activation= activation)
            elif mod == 'RNN':
                m =  KerasRegressor(model=RNN_Model, input_dim=input_dim, output_dim=output_dim, units =32, learning_rate = 0.0001, activation= activation)
                
            
            random_search = RandomizedSearchCV(m, param_distributions=param_dist, cv=3, n_iter=10, n_jobs=-1, scoring='neg_mean_squared_error')
            random_search.fit(eda.X_valid, eda.y_valid)
            #LÆ°u tham sá»‘ sau khi optimize
            torch.save({
            'model': random_search,
            'best_params':random_search.best_params_
            }, "./model/Optimize_Model.pth")
            st.write("Best Parameters:", random_search.best_params_)

            #In thá»i gian optimize
            optimize_time = "{:.4f}".format((time.time() * 1000) - (start_time * 1000))
            st.write(f"Thá»i gian Optimize {optimize_time}ms")
            st.session_state.optimize_time = optimize_time
            st.session_state.display_info['best_params'] = random_search.best_params_
            st.write("Optimize Complete!")
    #Traing Model        
    if st.sidebar.button('Train Model'):
        st.divider()
        st.header("Huáº¥n luyá»‡n MÃ´ HÃ¬nh")
        st.subheader('MÃ´ hÃ¬nh Ä‘Ã£ optimize')
        #Load siÃªu tham sá»‘ sau khi optimize
        model_op = torch.load("./model/Optimize_Model.pth")
        st.session_state.display_info = model_op['best_params']
        st.write(st.session_state.display_info)
        start_time_train = time.time()
        with st.spinner("Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh vá»›i bá»™ siÃªu tham sá»‘..."):
            # Láº¥y bá»™ tham sá»‘ tá»‘t nháº¥t tá»« quÃ¡ trÃ¬nh optimize
            best_params =  model_op['best_params']
            if mod == 'CNN':
                m1 = CNN_Model(input_dim=input_dim, output_dim=output_dim, units = best_params['units'], learning_rate = best_params['learning_rate'], activation= activation)
            elif mod == 'LSTM':
                m1 = LSTM_Model(input_dim=input_dim, output_dim=output_dim, units = best_params['units'], learning_rate = best_params['learning_rate'], activation= activation)
            elif mod == 'RNN':
                m1 = RNN_Model(input_dim=input_dim, output_dim=output_dim, units = best_params['units'], learning_rate = best_params['learning_rate'], activation= activation)
            #Tiáº¿n hÃ nh training
            model_training = eda.train_model(m1,epochs=best_params['epochs'], batch_size=best_params['batch_size'])

            st.session_state.model_training = model_training

            #LÆ°u cÃ¡c paramter vÃ o file Model.pth
            torch.save({
            'model': model_training,
            'units': best_params['units'],
            'epochs': best_params['epochs'],
            'batch_size': best_params['batch_size'],
            'learning_rate': best_params['learning_rate']
            }, "./model/Model.pth")

            train_time = "{:.4f}".format((time.time() * 1000) - (start_time_train* 1000))
            st.write(f"Thá»i gian Training {train_time}ms")
            st.session_state.train_time = train_time
            st.write("Training Complete!")
    #Retain Model
    if st.sidebar.button('Retrain Model'):
        st.divider()
        st.header("Huáº¥n luyá»‡n MÃ´ HÃ¬nh")
        start_time_train = time.time()
        with st.spinner("Äang retrain mÃ´ hÃ¬nh vá»›i táº­p dá»¯ liá»‡u..."):
            if mod == 'CNN':
                 m=CNN_Retrain(input_dim=input_dim,output_dim=output_dim)
            #SiÃªu tham sá»‘ 
            epochs, batch_size = 20, 4
            #Tiáº¿n hÃ nh train
            model_training = eda.train_model(m,epochs=epochs, batch_size=batch_size)
            st.session_state.model_training = model_training

            #LÆ°u cÃ¡c paramter vÃ o file Model.pth
            torch.save({
            'model': model_training,
            'units': 16,
            'epochs': epochs,
            'batch_size': batch_size,
            'learning_rate': None
            }, "./model/Model.pth")
            #In thá»i gian 
            train_time = "{:.4f}".format((time.time() * 1000) - (start_time_train* 1000))
            st.write(f"Thá»i gian Training {train_time}ms")
            st.session_state.train_time = train_time
            st.write("Training Complete!")

    if model_training!=None:
        st.subheader("Trá»ng sá»‘ cá»§a tá»«ng lá»›p")
        for layer in model_training.layers:
            if len(layer.get_weights()) > 0:
                st.write(f"Layer {layer.name} - Weights:")
                weights = layer.get_weights()
                for i, w in enumerate(weights):
                    st.write(f"Weight {i + 1}:")
                    w_flattened = np.array(w).flatten()
                    df = pd.DataFrame(w_flattened)
                    st.write(df)
                st.write("\n")

#Load táº­p dá»¯ liá»‡u test
st.header("Chá»n táº­p dá»¯ liá»‡u tiáº¿n hÃ nh dá»± Ä‘oÃ¡n")
uploaded_file1 = st.file_uploader(
"Chá»n tá»‡p dá»¯ liá»‡u test", type=["csv"],on_change=ClearCache)

# Náº¿u Ä‘Ã£ upload file
if uploaded_file1 is not None:
    file_name_test = uploaded_file1.name
    df_test = LoadData(uploaded_file1)
    
    #Chá»n cá»™t Ä‘á»ƒ dá»± Ä‘oÃ¡n
    selected_predict_column_name_test = st.sidebar.selectbox(
    '**Chá»n cá»™t Ä‘á»ƒ dá»± Ä‘oÃ¡n:**', tuple(df_test.drop(df_test.columns[0],axis = 1).columns.values), on_change=ClearCache)

    # Táº¡o Ä‘á»‘i tÆ°á»£ng EDA
    eda = EDA(df = df_test, n_steps_in = input_dim, n_steps_out = output_dim, feature=selected_predict_column_name_test, train_ratio = 0, valid_ratio = 0, scaler = scaler)
    # ThÃ´ng tin táº­p dá»¯ liá»‡u
    st.subheader('Táº­p dá»¯ liá»‡u test ' + file_name_test)
    st.write(df_test)

    # Váº½ biá»ƒu Ä‘á»“ Ä‘Æ°á»ng cho táº­p dá»¯ liá»‡u
    st.subheader('Trá»±c quan hÃ³a táº­p dá»¯ liá»‡u ' + file_name_test)

    column_names_test = eda.data_old.columns.tolist()
    selected_column_name_test = st.selectbox("**Chá»n cá»™t váº½ biá»ƒu Ä‘á»“:**", column_names_test)
    fig_test = MultipleLines.OneLine(eda, selected_column_name_test)
    st.plotly_chart(fig_test)

    #Thá»±c hiá»‡n nÃºt test model
    st.sidebar.button('Test Model', type="primary", on_click= click_button_train)   
    if st.session_state.clicked_train:
        # try:
            # Load cÃ¡c paramter Ä‘Æ°á»£c lÆ°u trong CNN_Model.pth
            checkpoint = torch.load("./model/Model.pth")

            unit_train = checkpoint["units"]
            epoch_train = checkpoint["epochs"]
            batch_size_train = checkpoint["batch_size"]
            LR_train = checkpoint["learning_rate"]
            model_train = checkpoint["model"]

            # Thá»ƒ hiá»‡n cÃ¡c giÃ¡ trá»‹ Ä‘Ã£ train lÃªn báº£ng vÃ  dÃ¹ng Ä‘á»ƒ test
            st.write("****CÃ¡c siÃªu tham sá»‘ Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ dá»± Ä‘oÃ¡n:****")
            train_table = pd.DataFrame(
                {"units": [unit_train],"epochs": [epoch_train], "batch_zize": [batch_size_train], "learning_rate": [LR_train]})
            st.table(train_table[:10])  

            # Thá»±c hiá»‡n test
            predict, actual, index, predict_scale, actua_scale = eda.TestingModel(model_train)

            # TÃ­nh lá»—i cá»§a táº­p dá»¯ liá»‡u vÃ  in ra mÃ n hÃ¬nh 
            mae, mse, rmse, mape, cv_rmse = Score(predict_scale,actua_scale)

            metrics = pd.DataFrame({
                "MAE": [mae],
                "MSE": [mse],
                "RMSE": [rmse],
                "MAPE": [mape],
                "CV_RMSE": [cv_rmse]})
            st.write("****ThÃ´ng sá»‘ lá»—i sau khi dá»± Ä‘oÃ¡n:****")
            st.table(metrics)
            st.write("****So sÃ¡nh káº¿t quáº£ dá»± Ä‘oÃ¡n vÃ  thá»±c táº¿:****")
            #TÃ­nh lá»—i trÃªn tá»«ng datapoint Ä‘á»ƒ xuáº¥t ra exel 
            mse_test = (predict_scale-actua_scale)**2
            # Kiá»ƒm tra káº¿t quáº£ dá»± Ä‘oÃ¡n vÃ  thá»±c táº¿ 
            if scaler != "Dá»¯ liá»‡u gá»‘c":
                result_test_table = pd.DataFrame(
                    {"NgÃ y" : index.tolist(),"GiÃ¡ trá»‹ dá»± Ä‘oÃ¡n": predict.tolist(), "GiÃ¡ trá»‹ thá»±c": actual.tolist(), "MSE": mse_test.tolist()})
            else:
                result_test_table = pd.DataFrame(
                    {"NgÃ y" : index.tolist(),"GiÃ¡ trá»‹ dá»± Ä‘oÃ¡n": predict_scale.tolist(), "GiÃ¡ trá»‹ thá»±c": actua_scale.tolist(), "MSE": mse_test.tolist()})
            st.session_state.result_test_table = result_test_table
            st.write(result_test_table)    



            # Biá»ƒu Ä‘á»“ so sÃ¡nh
            compare_date = st.selectbox("****Chá»n ngÃ y Ä‘á»ƒ so sÃ¡nh káº¿t quáº£ dá»± Ä‘oÃ¡n****",list(range(1,output_dim+1)))
            mline = MultipleLines.MultipLines(predict_scale[:,compare_date-1], actua_scale[:,compare_date-1], index)
            st.plotly_chart(mline)

            csv_output = [result_test_table,metrics, train_table]

            # list of sheet names
            sheets = ['Result test','metrics', 'train parameters']  

            #Download káº¿t quáº£ vá» file excel
            st.download_button(label='ğŸ“¥ Download Current Result',
                                data=dfs_tabs(csv_output, sheets) ,
                                file_name= 'Result-test.xlsx')           
        # except:
        #     st.error("****Hiá»‡n táº¡i chÆ°a cÃ³ Model!****")