import time
import io
import math 
import torch
import pandas as pd
import numpy as np
from EDA import EDA
from Multiple_Lines import MultipleLines
import streamlit as st
import tensorflow as tf
from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, make_scorer
from sklearn.model_selection import KFold
from sklearn.model_selection import RandomizedSearchCV
from scikeras.wrappers import KerasRegressor
from tensorflow.keras.layers import Dense, LSTM, Conv1D, LeakyReLU, Flatten, MaxPooling1D, SimpleRNN
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
tf.get_logger().setLevel('ERROR')

st.set_page_config(page_title="Forecast Time Series",page_icon=":bar_chart:",layout="centered")

st.write("# D·ª∞ ƒêO√ÅN B·∫∞NG M·∫†NG N∆†-RON T√çCH CH·∫¨P (CONVOLUTIONAL NEURAL NETWORK)")
st.divider()
st.sidebar.write("# Thi·∫øt l·∫≠p m√¥ h√¨nh")

# ------------------------- Bi·∫øn to√†n c·ª•c ------------------------- #
df = None
df_target = None
df_scaled = None
model = None
d = None
t = None
train_size = None
degree = None
unit = None
epoch= None
batch_size = None
m = None
scaler = None
test_size = None
train = None
test = None
train_time = None
test_time = None
predict = None
actual = None
info_table = None
result_table = None
metric_table = None
metrics = None
learning_rate = None
generator = None
discriminator = None

# ------------------------- Function ------------------------- #
# load data.csv
@st.cache_data
def LoadData(uploaded_file):
    df = pd.read_csv(uploaded_file)
    return df

#T√≠nh CV_RMSE
@st.cache_data
def CV_RMSE(predict, actual):
    # S·ªë l∆∞·ª£ng fold (ch·∫≥ng h·∫°n, 5-fold cross-validation)
    num_folds = 5

    # Kh·ªüi t·∫°o K-fold cross-validation
    kf = KFold(n_splits=num_folds)
    # T·∫°o danh s√°ch ƒë·ªÉ l∆∞u k·∫øt qu·∫£ RMSE t·ª´ t·ª´ng fold
    rmse_scores = []

    for train_index, test_index in kf.split(actual):
        predicted_test, actual_test = predict[test_index], actual[test_index]
        
        mse = mean_squared_error(actual_test, predicted_test)
        rmse = math.sqrt(mse)
        
        rmse_scores.append(rmse)

    # T√≠nh t·ªïng RMSE t·ª´ c√°c fold v√† t√≠nh RMSE trung b√¨nh
    average_rmse = np.mean(rmse_scores)
    return average_rmse

# H√†m ƒë√°nh gi√°
@st.cache_data
def Score(predict, actual):
    mae = mean_absolute_error(actual, predict)
    mse = mean_squared_error(actual, predict)
    rmse = np.sqrt(mse)
    mape = np.mean(np.abs((actual - predict) / predict))
    cv_rmse = CV_RMSE(predict,actual)
    return mae, mse, rmse ,mape ,cv_rmse



# X√≥a d·ªØ li·ªáu l∆∞u trong streamlit
def ClearCache():
    st.session_state.clear()

def dfs_tabs(df_list, sheet_list):

    output = io.BytesIO()

    writer = pd.ExcelWriter(output,engine='xlsxwriter')   
    for dataframe, sheet in zip(df_list, sheet_list):
        dataframe.to_excel(writer, sheet_name=sheet, startrow=0 , startcol=0)   
    writer.close()

    processed_data = output.getvalue()
    return processed_data

if 'clicked_train' not in st.session_state:
    st.session_state.clicked_train = False

def click_button_train():
    st.session_state.clicked_train = True

if 'clicked_save' not in st.session_state:
    st.session_state.clicked_save = False
if 'display_info' not in st.session_state:
        st.session_state.display_info = {}
def click_button_save():
    st.session_state.clicked_save = True
    

#--------------------------------------
# Sidebar
# Ch·ªçn m√¥ h√¨nh
mod = st.sidebar.selectbox(
    "Ch·ªçn m√¥ h√¨nh:",
    ["CNN", "LSTM","RNN"],
    on_change=ClearCache).lstrip('*').rstrip('*')

# Ch·ªçn ng√†y ƒë·ªÉ d·ª± ƒëo√°n
col1, col2 = st.sidebar.columns(2)
with col1:
    input_dim = st.number_input('**S·ªë ng√†y d√πng ƒë·ªÉ d·ª± ƒëo√°n:**',
                            value=7, step=1, min_value=1, on_change=ClearCache)

with col2:
    output_dim = st.number_input('**S·ªë ng√†y mu·ªën d·ª± ƒëo√°n:**', value=1,
                            step=1, min_value=1, on_change=ClearCache)

# Ch·ªçn t·ªâ l·ªá chia t·∫≠p train/test
train_size = st.sidebar.slider('**T·ªâ l·ªá training**', 10, 70, 70, step=10)
valid_size = st.sidebar.slider('**T·ªâ l·ªá Validation**', 10, 90 - train_size, 20, step=10)
train_ratio = train_size/100
valid_ratio = valid_size/100

activation = st.sidebar.selectbox(
    '**Ch·ªçn Activation funcion**', ('ReLU', 'LeakyReLU', 'tanh'), on_change=ClearCache)


scaler = st.sidebar.selectbox(
    '**Ch·ªçn ph∆∞∆°ng ph√°p chu·∫©n h√≥a d·ªØ li·ªáu**', ('Min-Max', 'Zero-Mean', 'D·ªØ li·ªáu g·ªëc'), on_change=ClearCache)

# Ch·ªçn t·∫≠p d·ªØ li·ªáu
st.header("Ch·ªçn t·∫≠p d·ªØ li·ªáu ti·∫øn h√†nh hu·∫•n luy·ªán")
uploaded_file = st.file_uploader(
    "Ch·ªçn t·ªáp d·ªØ li·ªáu", type=["csv"], on_change=ClearCache)


def LSTM_Model(input_dim=10, output_dim=1, units =32, learning_rate=0.0001, activation = 'relu') -> tf.keras.models.Model:
    model = Sequential()
    model.add(LSTM(units=units, return_sequences=True, input_shape=(input_dim, 1), activation=activation))
    model.add(LSTM(units=units, activation=activation))
    model.add(Dense(32, activation=activation))
    model.add(Dense(units=output_dim))
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')
    return model

def RNN_Model(input_dim=10, output_dim=1, units =32, learning_rate=0.0001, activation = 'relu') -> tf.keras.models.Model:
    model = Sequential()
    model.add(SimpleRNN(units=units, return_sequences=True, input_shape=(input_dim, 1), activation=activation))
    model.add(SimpleRNN(units=units, activation=activation))
    model.add(Dense(32, activation=activation))
    model.add(Dense(units=output_dim))

    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')
    return model

def CNN_Model(input_dim=10, output_dim=1, units = 32, learning_rate = 0.0001, activation = 'relu'):
    model = Sequential()
    # Th√™m l·ªõp Convolutional 1D ƒë·∫ßu ti√™n
    model.add(Conv1D(units, input_shape=(input_dim, 1), kernel_size=3, strides=1, padding='same', activation=activation)) 
    model.add(Conv1D(units, kernel_size=3, strides=1, padding='same', activation=activation))
    model.add(MaxPooling1D(pool_size=2,strides=2, padding='same'))
    # Ho√†n thi·ªán m√¥ h√¨nh
    model.add(Flatten())
    model.add(Dense(220, use_bias=True))
    model.add(LeakyReLU())
    model.add(Dense(220, use_bias=True, activation=activation))
    model.add(Dense(units=output_dim))
    # Thi·∫øt l·∫≠p c·∫•u h√¨nh cho m√¥ h√¨nh ƒë·ªÉ s·∫µn s√†ng cho qu√° tr√¨nh hu·∫•n luy·ªán.
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')
    return model
def CNN_Retrain(input_dim=10, output_dim=1):
    # define model
    model = Sequential()
    model.add(Conv1D(filters=16, kernel_size=3, activation='relu', input_shape=(input_dim,1)))
    model.add(MaxPooling1D(pool_size=2))
    model.add(Flatten())
    model.add(Dense(10, activation='relu'))
    model.add(Dense(output_dim))
    model.compile(loss='mse', optimizer='adam')
    return model

if uploaded_file is not None:
    file_name = uploaded_file.name
    df = LoadData(uploaded_file)

    # Ch·ªçn c·ªôt d·ª± ƒëo√°n & activation function
    selected_predict_column_name = st.sidebar.selectbox(
        '**Ch·ªçn c·ªôt ƒë·ªÉ ti·∫øn h√†nh training:**', tuple(df.drop(df.columns[0],axis = 1).columns.values), on_change=ClearCache)
    # T·∫°o ƒë·ªëi t∆∞·ª£ng EDA
    eda = EDA(df = df, n_steps_in = input_dim, n_steps_out = output_dim, feature=selected_predict_column_name, train_ratio = train_ratio, valid_ratio = valid_ratio, scaler = scaler)

    # Th√¥ng tin t·∫≠p d·ªØ li·ªáu
    st.subheader('T·∫≠p d·ªØ li·ªáu ' + file_name)
    st.write(df)

    # V·∫Ω bi·ªÉu ƒë·ªì ƒë∆∞·ªùng cho t·∫≠p d·ªØ li·ªáu
    st.subheader('Tr·ª±c quan h√≥a t·∫≠p d·ªØ li·ªáu ' + file_name)

    column_names = eda.data_old.columns.tolist()
    selected_column_name = st.selectbox("**Ch·ªçn c·ªôt:**", column_names)
    fig = MultipleLines.OneLine(eda, selected_column_name)
    st.plotly_chart(fig)

    df_target = df[selected_column_name]
    
    # Optimize Model
    if st.sidebar.button('Optimize Model', type="primary"):
        st.divider()
        st.header("Optimize M√¥ H√¨nh")
        with st.spinner('ƒêang ti·∫øn h√†nh Optimize...'):
            start_time = time.time()
            
            param_dist = {
            'units': [16, 32, 64, 128, 256],
            'epochs': range(1, 101),
            'batch_size': [16, 32, 64, 128, 256],
            'learning_rate': [0.0001]
            }
            if mod == 'CNN':
                m = KerasRegressor(model = CNN_Model, input_dim=input_dim, output_dim=output_dim, units =32, learning_rate = 0.0001, activation= activation)

            elif mod == 'LSTM':
                m =  KerasRegressor(model=LSTM_Model, input_dim=input_dim, output_dim=output_dim, units =32, learning_rate = 0.0001, activation= activation)
            elif mod == 'RNN':
                m =  KerasRegressor(model=RNN_Model, input_dim=input_dim, output_dim=output_dim, units =32, learning_rate = 0.0001, activation= activation)
                
            
            random_search = RandomizedSearchCV(m, param_distributions=param_dist, cv=3, n_iter=10, n_jobs=-1, scoring='neg_mean_squared_error')
            random_search.fit(eda.X_valid, eda.y_valid)
            #L∆∞u tham s·ªë sau khi optimize
            torch.save({
            'model': random_search,
            'best_params':random_search.best_params_
            }, "./model/Optimize_Model.pth")
            st.write("Best Parameters:", random_search.best_params_)

            #In th·ªùi gian optimize
            optimize_time = "{:.4f}".format((time.time() * 1000) - (start_time * 1000))
            st.write(f"Th·ªùi gian Optimize {optimize_time}ms")
            st.session_state.optimize_time = optimize_time
            st.session_state.display_info['best_params'] = random_search.best_params_
            st.write("Optimize Complete!")
    #Traing Model        
    if st.sidebar.button('Train Model'):
        st.divider()
        st.header("Hu·∫•n luy·ªán M√¥ H√¨nh")
        st.subheader('M√¥ h√¨nh ƒë√£ optimize')
        #Load si√™u tham s·ªë sau khi optimize
        model_op = torch.load("./model/Optimize_Model.pth")
        st.session_state.display_info = model_op['best_params']
        st.write(st.session_state.display_info)
        start_time_train = time.time()
        with st.spinner("ƒêang hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi b·ªô si√™u tham s·ªë..."):
            # L·∫•y b·ªô tham s·ªë t·ªët nh·∫•t t·ª´ qu√° tr√¨nh optimize
            best_params =  model_op['best_params']
            if mod == 'CNN':
                m1 = CNN_Model(input_dim=input_dim, output_dim=output_dim, units = best_params['units'], learning_rate = best_params['learning_rate'], activation= activation)
            elif mod == 'LSTM':
                m1 = LSTM_Model(input_dim=input_dim, output_dim=output_dim, units = best_params['units'], learning_rate = best_params['learning_rate'], activation= activation)
            elif mod == 'RNN':
                m1 = RNN_Model(input_dim=input_dim, output_dim=output_dim, units = best_params['units'], learning_rate = best_params['learning_rate'], activation= activation)
            #Ti·∫øn h√†nh training
            model_training = eda.train_model(m1,epochs=best_params['epochs'], batch_size=best_params['batch_size'])

            st.session_state.model_training = model_training

            #L∆∞u c√°c paramter v√†o file Model.pth
            torch.save({
            'model': model_training,
            'units': best_params['units'],
            'epochs': best_params['epochs'],
            'batch_size': best_params['batch_size'],
            'learning_rate': best_params['learning_rate']
            }, "./model/Model.pth")

            train_time = "{:.4f}".format((time.time() * 1000) - (start_time_train* 1000))
            st.write(f"Th·ªùi gian Training {train_time}ms")
            st.session_state.train_time = train_time
            st.write("Training Complete!")
    #Retain Model
    if st.sidebar.button('Retrain Model'):
        st.divider()
        st.header("Hu·∫•n luy·ªán M√¥ H√¨nh")
        start_time_train = time.time()
        with st.spinner("ƒêang retrain m√¥ h√¨nh v·ªõi t·∫≠p d·ªØ li·ªáu..."):
            if mod == 'CNN':
                 m=CNN_Retrain(input_dim=input_dim,output_dim=output_dim)
            #Si√™u tham s·ªë 
            epochs, batch_size = 20, 4
            #Ti·∫øn h√†nh train
            model_training = eda.train_model(m,epochs=epochs, batch_size=batch_size)
            st.session_state.model_training = model_training

            #L∆∞u c√°c paramter v√†o file Model.pth
            torch.save({
            'model': model_training,
            'units': 16,
            'epochs': epochs,
            'batch_size': batch_size,
            'learning_rate': None
            }, "./model/Model.pth")
            #In th·ªùi gian 
            train_time = "{:.4f}".format((time.time() * 1000) - (start_time_train* 1000))
            st.write(f"Th·ªùi gian Training {train_time}ms")
            st.session_state.train_time = train_time
            st.write("Training Complete!")

#Load t·∫≠p d·ªØ li·ªáu test
st.header("Ch·ªçn t·∫≠p d·ªØ li·ªáu ti·∫øn h√†nh d·ª± ƒëo√°n")
uploaded_file1 = st.file_uploader(
"Ch·ªçn t·ªáp d·ªØ li·ªáu test", type=["csv"],on_change=ClearCache)

# N·∫øu ƒë√£ upload file
if uploaded_file1 is not None:
    file_name_test = uploaded_file1.name
    df_test = LoadData(uploaded_file1)
    
    #Ch·ªçn c·ªôt ƒë·ªÉ d·ª± ƒëo√°n
    selected_predict_column_name_test = st.sidebar.selectbox(
    '**Ch·ªçn c·ªôt ƒë·ªÉ d·ª± ƒëo√°n:**', tuple(df_test.drop(df_test.columns[0],axis = 1).columns.values), on_change=ClearCache)

    # T·∫°o ƒë·ªëi t∆∞·ª£ng EDA
    eda = EDA(df = df_test, n_steps_in = input_dim, n_steps_out = output_dim, feature=selected_predict_column_name_test, train_ratio = 0, valid_ratio = 0, scaler = scaler)
    # Th√¥ng tin t·∫≠p d·ªØ li·ªáu
    st.subheader('T·∫≠p d·ªØ li·ªáu test ' + file_name_test)
    st.write(df_test)

    # V·∫Ω bi·ªÉu ƒë·ªì ƒë∆∞·ªùng cho t·∫≠p d·ªØ li·ªáu
    st.subheader('Tr·ª±c quan h√≥a t·∫≠p d·ªØ li·ªáu ' + file_name_test)

    column_names_test = eda.data_old.columns.tolist()
    selected_column_name_test = st.selectbox("**Ch·ªçn c·ªôt v·∫Ω bi·ªÉu ƒë·ªì:**", column_names_test)
    fig_test = MultipleLines.OneLine(eda, selected_column_name_test)
    st.plotly_chart(fig_test)

    #Th·ª±c hi·ªán n√∫t test model
    st.sidebar.button('Test Model', type="primary", on_click= click_button_train)   
    if st.session_state.clicked_train:
        # try:
            # Load c√°c paramter ƒë∆∞·ª£c l∆∞u trong CNN_Model.pth
            checkpoint = torch.load("./model/Model.pth")

            unit_train = checkpoint["units"]
            epoch_train = checkpoint["epochs"]
            batch_size_train = checkpoint["batch_size"]
            LR_train = checkpoint["learning_rate"]
            model_train = checkpoint["model"]

            # Th·ªÉ hi·ªán c√°c gi√° tr·ªã ƒë√£ train l√™n b·∫£ng v√† d√πng ƒë·ªÉ test
            st.write("****C√°c si√™u tham s·ªë ƒë∆∞·ª£c d√πng ƒë·ªÉ d·ª± ƒëo√°n:****")
            train_table = pd.DataFrame(
                {"units": [unit_train],"epochs": [epoch_train], "batch_zize": [batch_size_train], "learning_rate": [LR_train]})
            st.table(train_table[:10])  

            # Th·ª±c hi·ªán test
            predict, actual, index, predict_scale, actua_scale = eda.TestingModel(model_train)
            st.write("****So s√°nh k·∫øt qu·∫£ d·ª± ƒëo√°n v√† th·ª±c t·∫ø:****")
            # Ki·ªÉm tra k·∫øt qu·∫£ d·ª± ƒëo√°n v√† th·ª±c t·∫ø 
            mse_test = (predict_scale-actua_scale)**2
            result_test_table = pd.DataFrame(
                {"Ng√†y" : index.tolist(),"Gi√° tr·ªã d·ª± ƒëo√°n": predict.tolist(), "Gi√° tr·ªã th·ª±c": actual.tolist(), "MSE": mse_test.tolist()})
            #T√≠nh l·ªói tr√™n t·ª´ng datapoint ƒë·ªÉ xu·∫•t ra exel 
            
            # result_test_table['MSE'] = mse_test
            
            # result_test_table['MSE'] = result_test_table['MSE'].apply(lambda x: format(x, '.10f'))

            st.session_state.result_test_table = result_test_table
            st.write(result_test_table)    

            # T√≠nh l·ªói c·ªßa t·∫≠p d·ªØ li·ªáu v√† in ra m√†n h√¨nh 
            mae, mse, rmse, mape, cv_rmse = Score(predict_scale,actua_scale)

            metrics = pd.DataFrame({
                "MAE": [mae],
                "MSE": [mse],
                "RMSE": [rmse],
                "MAPE": [mape],
                "CV_RMSE": [cv_rmse]})
            st.write("****Th√¥ng s·ªë l·ªói sau khi d·ª± ƒëo√°n:****")
            st.table(metrics)

            # Bi·ªÉu ƒë·ªì so s√°nh
            compare_date = st.selectbox("****Ch·ªçn ng√†y ƒë·ªÉ so s√°nh k·∫øt qu·∫£ d·ª± ƒëo√°n****",list(range(1,output_dim+1)))
            mline = MultipleLines.MultipLines(predict[:,compare_date-1], actual[:,compare_date-1], index)
            st.plotly_chart(mline)

            csv_output = [result_test_table,metrics, train_table]

            # list of sheet names
            sheets = ['Result test','metrics', 'train parameters']  

            #Download k·∫øt qu·∫£ v·ªÅ file excel
            st.download_button(label='üì• Download Current Result',
                                data=dfs_tabs(csv_output, sheets) ,
                                file_name= 'Result-test.xlsx')           
        # except:
        #     st.error("****Hi·ªán t·∫°i ch∆∞a c√≥ Model!****")