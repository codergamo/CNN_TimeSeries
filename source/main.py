import time
import os
import io
import xlwings as xlw
import math 
import torch
import xlsxwriter
import win32com.client
import openpyxl
from openpyxl.utils.dataframe import dataframe_to_rows
import pandas as pd
import numpy as np
from EDA import EDA
from Multiple_Lines import MultipleLines
import streamlit as st
import plotly.graph_objs as go
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dense, Dropout, SimpleRNN, GRU, LSTM
from keras.callbacks import Callback
from streamlit.logger import get_logger
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split, KFold
from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, make_scorer
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from kerastuner.tuners import RandomSearch
import xlsxwriter
from openpyxl.styles import Font


st.set_page_config(page_title="Forecast Time Series",page_icon=":bar_chart:",layout="centered")

st.write("# D·ª∞ ƒêO√ÅN B·∫∞NG M·∫†NG N∆†-RON T√çCH CH·∫¨P (CONVOLUTIONAL NEURAL NETWORK)")
st.divider()
st.sidebar.write("# Thi·∫øt l·∫≠p m√¥ h√¨nh")

# ------------------------- Bi·∫øn to√†n c·ª•c ------------------------- #
df = None
df_target = None
df_scaled = None
model = None
d = None
t = None
train_size = None
degree = None
unit = None
epoch= None
batch_size = None
m = None
scaler = None
test_size = None
train = None
test = None
train_time = None
test_time = None
predict = None
actual = None
info_table = None
result_table = None
metric_table = None
metrics = None
learning_rate = None
generator = None
discriminator = None

# ------------------------- Function ------------------------- #
# load data.csv
@st.cache_data
def LoadData(uploaded_file):
    df = pd.read_csv(uploaded_file)
    return df



def CV_RMSE(predict, actual):
    # S·ªë l∆∞·ª£ng fold (ch·∫≥ng h·∫°n, 5-fold cross-validation)
    num_folds = 5

    # Kh·ªüi t·∫°o K-fold cross-validation
    kf = KFold(n_splits=num_folds)

    # T·∫°o danh s√°ch ƒë·ªÉ l∆∞u k·∫øt qu·∫£ RMSE t·ª´ t·ª´ng fold
    rmse_scores = []

    for train_index, test_index in kf.split(actual):
        predicted_test, actual_test = predict[test_index], actual[test_index]
        
        mse = mean_squared_error(actual_test, predicted_test)
        rmse = math.sqrt(mse)
        
        rmse_scores.append(rmse)

    # T√≠nh t·ªïng RMSE t·ª´ c√°c fold v√† t√≠nh RMSE trung b√¨nh
    average_rmse = np.mean(rmse_scores)
    return average_rmse

# Function to save all dataframes to one single excel

def to_excel(df):
    output = io.BytesIO()
    writer = pd.ExcelWriter(output, engine='xlsxwriter')
    df[0].to_excel(writer, index=False, sheet_name='Result Test')
    df[1].to_excel(writer, index=False, sheet_name='Metrics')
    workbook = writer.book
    worksheet1 = writer.book
    worksheet = writer.sheets['Result Test']
    worksheet1 = writer.sheets['Metrics']

    format1 = workbook.add_format({'num_format': '0.00'}) 

    worksheet.set_column('A:A', None, format1) 
    worksheet1.set_column('A:A', None, format1) 
    writer.close()
    processed_data = output.getvalue()
    st.download_button(label='üì• Download Current Result',
                                data=processed_data,
                                file_name= 'report.xlsx')
    # return processed_data

# H√†m ƒë√°nh gi√°
@st.cache_data
def Score(predict, actual):
    mae = mean_absolute_error(actual, predict)
    mse = mean_squared_error(actual, predict)
    rmse = np.sqrt(mse)
    mape = mean_absolute_percentage_error(actual, predict)
    cv_rmse = CV_RMSE(predict,actual)
    return mae, mse, rmse ,mape ,cv_rmse
#T√≠nh CV_RMSE
@st.cache_data
def CV_RMSE(predict,actual):
    num_folds = 5
    rmse_scores = []
    kf = KFold(n_splits=num_folds)
    for train_index, test_index in kf.split(actual):
        actual_test, predicted_test = actual[test_index], predict[test_index]
    
        mse = mean_squared_error(actual_test, predicted_test)
        rmse = np.sqrt(mse)
        
        rmse_scores.append(rmse)
    average_rmse = np.mean(rmse_scores)
    return average_rmse

# X√≥a d·ªØ li·ªáu l∆∞u trong streamlit
def ClearCache():
    st.session_state.clear()

def dfs_tabs(df_list, sheet_list):

    output = io.BytesIO()

    writer = pd.ExcelWriter(output,engine='xlsxwriter')   
    for dataframe, sheet in zip(df_list, sheet_list):
        dataframe.to_excel(writer, sheet_name=sheet, startrow=0 , startcol=0)   
    writer.close()

    processed_data = output.getvalue()
    return processed_data

def to_excel(df):
    output = io.BytesIO()
    writer = pd.ExcelWriter(output, engine='xlsxwriter')
    df.to_excel(writer, index=False, sheet_name='Sheet1')
    workbook = writer.book
    worksheet = writer.sheets['Sheet1']
    format1 = workbook.add_format({'num_format': '0.00'}) 
    worksheet.set_column('A:A', None, format1)  
    writer.close()
    processed_data = output.getvalue()
    
    return processed_data
if 'clicked_train' not in st.session_state:
    st.session_state.clicked_train = False

def click_button_train():
    st.session_state.clicked_train = True

if 'clicked_save' not in st.session_state:
    st.session_state.clicked_save = False

def click_button_save():
    st.session_state.clicked_save = True

#--------------------------------------
# Sidebar
# Ch·ªçn m√¥ h√¨nh
model = st.sidebar.selectbox(
    "Ch·ªçn m√¥ h√¨nh:",
    ["CNN", "LSTM"],
    on_change=ClearCache).lstrip('*').rstrip('*')

# Ch·ªçn ng√†y ƒë·ªÉ d·ª± ƒëo√°n
col1, col2 = st.sidebar.columns(2)
with col1:
    input_dim = st.number_input('**S·ªë ng√†y d√πng ƒë·ªÉ d·ª± ƒëo√°n:**',
                            value=7, step=1, min_value=1, on_change=ClearCache)

with col2:
    output_dim = st.number_input('**S·ªë ng√†y mu·ªën d·ª± ƒëo√°n:**', value=1,
                            step=1, min_value=1, on_change=ClearCache)

# Ch·ªçn t·ªâ l·ªá chia t·∫≠p train/test
train_size = st.sidebar.slider('**T·ªâ l·ªá training**', 10, 90, 80, step=10)
split_ratio = train_size/100

# Ch·ªçn SL Epoch & SL Batch Size
col3, col4 = st.sidebar.columns(2)
with col3:
    epochs = st.number_input(
        '**Epoch**', value=3, step=1, min_value=1, on_change=ClearCache)
with col4:
    feature_loop = st.number_input(
        '**Feature_Loop**', value=1, step=1, min_value=1, on_change=ClearCache)



batch_size = st.sidebar.selectbox(
    '**Batch Size**', (16, 32, 64, 128, 256, 512), on_change=ClearCache)


# Ch·ªçn t·ªëc ƒë·ªô h·ªçc
default_value = 0.0001
learning_rate = st.sidebar.number_input("**Learning Rate**", value=default_value, step=0.00005, min_value=0.0000, format="%.5f")



activation = st.sidebar.selectbox(
    '**Ch·ªçn Activation funcion**', ('ReLU', 'sigmoid', 'tanh'), on_change=ClearCache)


scaler = st.sidebar.selectbox(
    '**Ch·ªçn ph∆∞∆°ng ph√°p chu·∫©n h√≥a d·ªØ li·ªáu**', ('Min-Max', 'Zero-Mean', 'D·ªØ li·ªáu g·ªëc'), on_change=ClearCache)

# Ch·ªçn t·∫≠p d·ªØ li·ªáu
st.header("Ch·ªçn t·∫≠p d·ªØ li·ªáu ti·∫øn h√†nh hu·∫•n luy·ªán")
uploaded_file = st.file_uploader(
    "Ch·ªçn t·ªáp d·ªØ li·ªáu", type=["csv"], on_change=ClearCache)


# T√¨m ra th√¥ng s·ªë cho m√¥ h√¨nh train c√≥ s·ªë l·ªói rmse nh·ªè nh·∫•t v√† l∆∞u v√†o th∆∞ m·ª•c
def hyper_paramter(m, rmse_min, rmse_loop, feature_step, feature_hyper, feature_train):  

    # Test model --> Tr·∫£ v·ªÅ gi√° tr·ªã d·ª± ƒëo√°n-th·ª±c t·∫ø rescale , ng√†y, gi√° tr·ªã d·ª± ƒëo√°n - th·ª±c t·∫ø scale
    predict, actual, index, predict_scale, actua_scale = eda.TestingModel(m)

    mae, mse, rmse, mape, cv_rmse = Score(predict_scale,actua_scale)
    # Th·ª±c hi·ªán t√≠nh l·ªói v·ªõi m·ªói gi√° tr·ªã ƒë√£ ƒë∆∞·ª£c scale

    rmse_loop.append(rmse)
    feature_train.append(feature_step)

    # N·∫øu gi√° tr·ªã rmse c≈© l·ªõn h∆°n rmse hi·ªán t·∫°i th√¨ l∆∞u gi√° tr·ªã hi·ªán t·∫°i
    if rmse < rmse_min:
        rmse_min = rmse
        feature_hyper = feature_step
        # L∆∞u model v√†o state hi·ªán t·∫°i
        st.session_state.m = m

        #L∆∞u c√°c paramter v√†o file CNN_Model.pth
        torch.save({
        'model': m,
        'epochs': epochs,
        'batch_size': batch_size,
        'feature_loop': feature_hyper
        }, "./model/CNN_Model.pth")

    # Tr·∫£ v·ªÅ gi√° tr·ªã d·ª± ƒëo√°n-th·ª±c t·∫ø rescale , ng√†y, gi√° tr·ªã d·ª± ƒëo√°n - th·ª±c t·∫ø scale, rmse nh·ªè nh·∫•t v√† s·ªë l·ªõp ·∫©n t∆∞∆°ng ·ª©ng
    return rmse_min, feature_hyper, rmse_loop, feature_train

if uploaded_file is not None:
    file_name = uploaded_file.name
    df = LoadData(uploaded_file)

    # Ch·ªçn c·ªôt d·ª± ƒëo√°n & activation function
    selected_predict_column_name = st.sidebar.selectbox(
        '**Ch·ªçn c·ªôt ƒë·ªÉ d·ª± ƒëo√°n:**', tuple(df.drop(df.columns[0],axis = 1).columns.values), on_change=ClearCache)
    # T·∫°o ƒë·ªëi t∆∞·ª£ng EDA
    eda = EDA(df = df, n_steps_in = input_dim, n_steps_out = output_dim, feature=selected_predict_column_name, split_ratio = split_ratio, scaler = scaler)

    # Th√¥ng tin t·∫≠p d·ªØ li·ªáu
    st.subheader('T·∫≠p d·ªØ li·ªáu ' + file_name)
    st.write(df)

    # V·∫Ω bi·ªÉu ƒë·ªì ƒë∆∞·ªùng cho t·∫≠p d·ªØ li·ªáu
    st.subheader('Tr·ª±c quan h√≥a t·∫≠p d·ªØ li·ªáu ' + file_name)

    column_names = eda.data_old.columns.tolist()
    selected_column_name = st.selectbox("**Ch·ªçn c·ªôt:**", column_names)
    fig = MultipleLines.OneLine(eda, selected_column_name)
    st.plotly_chart(fig)

    df_target = df[selected_column_name]
    
    # Training
    if st.sidebar.button('Train Model', type="primary"):
        st.divider()
        st.header("Hu·∫•n Luy·ªán M√¥ H√¨nh")
        with st.spinner('ƒêang ti·∫øn h√†nh training...'):
            start_time = time.time()
            rmse_min = 1
            rmse_loop = []
            feature_hyper = 0
            feature_train = []
            if model == 'CNN':
                for feature_step in range (feature_loop , 11):
                    #Truy·ªÅn c√°c th√¥ng s·ªë v√†o model
                    m = eda.CNN_Model(input_dim , output_dim , feature_size = 1, epochs=epochs , batch_size=batch_size, activation=activation, learning_rate=learning_rate, feature_step = feature_step)

                    # Tr·∫£ v·ªÅ gi√° tr·ªã rmse nh·ªè nh·∫•t, s·ªë l·ªõp ·∫©n t∆∞∆°ng ·ª©ng
                    rmse_min, feature_hyper, rmse_loop, feature_train = hyper_paramter(m, rmse_min, rmse_loop, feature_step, feature_hyper, feature_train)
          
            elif model == 'LSTM':
                m = eda.LSTM_Model(input_dim , output_dim , feature_size = 1, epochs=epochs, batch_size=batch_size, activation=activation, learning_rate=learning_rate)
            

            # In k·∫øt qu·∫£ sau khi train
            ## S·ªë l·ªói c√°c v√≤ng l·∫∑p v√† th√¥ng s·ªë v√≤ng c√≥ l·ªói nh·ªè nh·∫•t
            
            # result_rmse_table = pd.DataFrame(
            #     {"rmse": rmse_loop, "feauture": feature_train})
            # st.table(result_rmse_table[:])

            st.write("Th√¥ng s·ªë c·ªßa v√≤ng l·∫∑p c√≥ RMSE nh·ªè nh·∫•t:")
            result_train_table = pd.DataFrame(
                {"epochs": [epochs], "batch_zize": [batch_size],"feature": [feature_hyper],"rmse": [rmse_min]})
            st.table(result_train_table[:])  

            #In th·ªùi gian training
            train_time = "{:.4f}".format((time.time() * 1000) - (start_time * 1000))
            st.write(f"Th·ªùi gian hu·∫•n luy·ªán {train_time}ms")
            st.session_state.train_time = train_time
            st.write("Training Complete!")

#Load t·∫≠p d·ªØ li·ªáu test
st.header("Ch·ªçn t·∫≠p d·ªØ li·ªáu ti·∫øn h√†nh d·ª± ƒëo√°n")
uploaded_file1 = st.file_uploader(
"Ch·ªçn t·ªáp d·ªØ li·ªáu test", type=["csv"],on_change=ClearCache)

# N·∫øu ƒë√£ upload file
if uploaded_file1 is not None:
    file_name_test = uploaded_file1.name
    df_test = LoadData(uploaded_file1)
    
    #Ch·ªçn c·ªôt ƒë·ªÉ d·ª± ƒëo√°n
    selected_predict_column_name_test = st.sidebar.selectbox(
    '**Ch·ªçn c·ªôt ƒë·ªÉ d·ª± ƒëo√°n Test:**', tuple(df_test.drop(df_test.columns[0],axis = 1).columns.values), on_change=ClearCache)

    # T·∫°o ƒë·ªëi t∆∞·ª£ng EDA
    eda = EDA(df = df_test, n_steps_in = input_dim, n_steps_out = output_dim, feature=selected_predict_column_name_test, split_ratio = split_ratio, scaler = scaler)
    # Th√¥ng tin t·∫≠p d·ªØ li·ªáu
    st.subheader('T·∫≠p d·ªØ li·ªáu test ' + file_name_test)
    st.write(df_test)

    # V·∫Ω bi·ªÉu ƒë·ªì ƒë∆∞·ªùng cho t·∫≠p d·ªØ li·ªáu
    st.subheader('Tr·ª±c quan h√≥a t·∫≠p d·ªØ li·ªáu ' + file_name_test)

    column_names_test = eda.data_old.columns.tolist()
    selected_column_name_test = st.selectbox("**Ch·ªçn c·ªôt v·∫Ω bi·ªÉu ƒë·ªì:**", column_names_test)
    fig_test = MultipleLines.OneLine(eda, selected_column_name_test)
    st.plotly_chart(fig_test)

    #Th·ª±c hi·ªán n√∫t test model
    st.sidebar.button('Test Model', type="primary", on_click= click_button_train)   
    if st.session_state.clicked_train:
        # try:
            # Load c√°c paramter ƒë∆∞·ª£c l∆∞u trong CNN_Model.pth
            checkpoint = torch.load("./model/CNN_Model.pth")

            test = checkpoint["model"]
            epoch_train = checkpoint["epochs"]
            feature_hyper_train = checkpoint["feature_loop"]
            batch_size_train = checkpoint["batch_size"]
            model_train = checkpoint["model"]

            # Th·ªÉ hi·ªán c√°c gi√° tr·ªã ƒë√£ train l√™n b·∫£ng v√† d√πng ƒë·ªÉ test
            train_table = pd.DataFrame(
                {"epochs": [epoch_train],"feature": [feature_hyper_train], "batch_zize": [batch_size_train]})
            st.table(train_table[:10])  

            # Th·ª±c hi·ªán test
            predict, actual, index, predict_scale, actua_scale = eda.TestingModel(test)

            # Ki·ªÉm tra k·∫øt qu·∫£ d·ª± ƒëo√°n v√† th·ª±c t·∫ø 
            result_test_table = pd.DataFrame(
                {"Ng√†y" : index.tolist(),"Gi√° tr·ªã d·ª± ƒëo√°n": predict.tolist(), "Gi√° tr·ªã th·ª±c": actual.tolist()})
            
            st.session_state.result_test_table = result_test_table
            st.table(result_test_table[:10])    

            # T√≠nh l·ªói c·ªßa t·∫≠p d·ªØ li·ªáu v√† in ra m√†n h√¨nh 
            mae, mse, rmse, mape, cv_rmse = Score(predict_scale,actua_scale)

            metrics = pd.DataFrame({
                "MAE": [mae],
                "MSE": [mse],
                "RMSE": [rmse],
                "MAPE": [mape],
                "CV_RMSE": [cv_rmse]})
            
            st.table(metrics)

            # Bi·ªÉu ƒë·ªì so s√°nh
            mline = MultipleLines.MultipLines(predict,actual, index)
            
            st.plotly_chart(mline)

            csv_output = [result_test_table,metrics, train_table]

            # list of sheet names
            sheets = ['Result test','metrics', 'train parameters']  

            #df_xlsx = dfs_tabs(csv_output, sheets, 'multi-test.xlsx')  

            #Download k·∫øt qu·∫£ v·ªÅ file excel
            st.download_button(label='üì• Download Current Result',
                                data=dfs_tabs(csv_output, sheets) ,
                                file_name= 'Result-test.xlsx')
            
        # except:
        #     st.write("Hi·ªán t·∫°i ch∆∞a c√≥ Model!")
            #L∆∞u k·∫øt qu·∫£ v·ªÅ th∆∞ m·ª•c hi·ªán h√†nh
            # st.button('L∆∞u d·ªØ li·ªáu Excel', type="secondary", on_click=click_button_save, key='save_button')
        # if st.clicked_save:
        #     # csv = result_test_table
        #     # csv.to_excel('./output/data.xlsx', engine='xlsxwriter')  
        #     st.success("Xu·∫•t d·ªØ li·ªáu th√†nh c√¥ng!!")
    

            
            
            
            
            
